{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Dataset/TextSummary/train.csv')\n",
    "dataX = data['document']\n",
    "dataY = data['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareFunction(string):\n",
    "    x = string.find('#')\n",
    "    if x == -1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for line in dataX:\n",
    "    X.append(list(filter(CompareFunction, line.split())))\n",
    "\n",
    "for line in dataY:\n",
    "    Y.append(list(filter(CompareFunction, line.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialWords = ['<unk>', '<start>', '<eos>', '<pad>']\n",
    "words = []\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "idx = 0\n",
    "\n",
    "for word in specialWords:\n",
    "    words.append(word)\n",
    "    word2idx[word] = idx\n",
    "    idx2word[idx] = word\n",
    "    idx += 1\n",
    "\n",
    "for line in X:\n",
    "    for word in line:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "for line in Y:\n",
    "    for word in line:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TurnDataIntoIndex(inputs, maxLength):\n",
    "    indexs = []\n",
    "    for sentence in inputs:\n",
    "        line = [word2idx[word] for word in sentence]\n",
    "        indexs.append([word2idx['<start>']] + line[0 : maxLength] + [word2idx['<eos>']] + [word2idx['<pad>']] * (maxLength - len(line)))\n",
    "    return indexs\n",
    "\n",
    "trainX = TurnDataIntoIndex(X, 70)\n",
    "trainX = np.array(trainX)\n",
    "dictLength = 33400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "通过trainX -> input 最后得到 Output\n",
    "'''\n",
    "inputY, outputY = [], []\n",
    "maxLengthY = 20\n",
    "for sentence in Y:\n",
    "    line = [word2idx[word] for word in sentence]\n",
    "    inputY.append([word2idx['<start>']] + line[0 : maxLengthY] + [word2idx['<pad>']] * (maxLengthY - len(line)))\n",
    "    outputY.append(line[0 : maxLengthY] + [word2idx['<eos>']] + [word2idx['<pad>']] * (maxLengthY - len(line)))\n",
    "\n",
    "inputY = np.array(inputY)\n",
    "outputY = np.array(outputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "class Seq2seqModel(Model):\n",
    "    def __init__(self, dictSize, outputDim, hiddenUnits):\n",
    "        super(Seq2seqModel, self).__init__()\n",
    "        self.encoderEmbedding = tf.keras.layers.Embedding(\n",
    "            input_dim = dictSize,\n",
    "            output_dim = outputDim\n",
    "        )\n",
    "        self.encoderLSTM = tf.keras.layers.LSTM(\n",
    "            hiddenUnits,\n",
    "            return_sequences = True,\n",
    "            return_state = True,\n",
    "            name = 'Encoder'\n",
    "        )\n",
    "\n",
    "        self.decoderEmbedding = tf.keras.layers.Embedding(\n",
    "            input_dim = dictSize,\n",
    "            output_dim = outputDim\n",
    "        )\n",
    "        self.decoderLSTM = tf.keras.layers.LSTM(\n",
    "            hiddenUnits,\n",
    "            return_sequences = True,\n",
    "            return_state = True,\n",
    "            name = 'Decoder'\n",
    "        )\n",
    "\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "\n",
    "        self.outputDense = tf.keras.layers.Dense(\n",
    "            dictSize,\n",
    "            activation = 'softmax',\n",
    "            name = 'OutputDense'\n",
    "        )\n",
    "\n",
    "    '''\n",
    "    Inputs[0] -> TrainX\n",
    "    Inputs[1] -> InputY\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        encoderEmbeddingOutput = self.encoderEmbedding(inputs[0])\n",
    "        encoderOutput, encoderStateH, encoderStateC = self.encoderLSTM(encoderEmbeddingOutput)\n",
    "\n",
    "        decoderEmbeddingOutput = self.decoderEmbedding(inputs[1])\n",
    "        decoderOutput, decoderStateH, decoderStateC = self.decoderLSTM(\n",
    "            decoderEmbeddingOutput,\n",
    "            initial_state = [\n",
    "                encoderStateH,\n",
    "                encoderStateC\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        attentionOutput = self.attention([decoderOutput, encoderOutput])\n",
    "\n",
    "        denseOutput = self.outputDense(attentionOutput)\n",
    "\n",
    "        return denseOutput\n",
    "    \n",
    "\n",
    "    def ModelInferenceSingle(self, inputs, word2idx, idx2word, maxLengthY):\n",
    "        sequence = [word2idx['<start>']]\n",
    "        result = []\n",
    "        states = {}\n",
    "\n",
    "        encoderEmbeddingOutput = self.encoderEmbedding(inputs)\n",
    "        encoderOutput, encoderStateH, encoderStateC = self.encoderLSTM(encoderEmbeddingOutput)\n",
    "\n",
    "        states[0] = [encoderStateH, encoderStateC]\n",
    "\n",
    "        for i in range(1, maxLengthY + 1):\n",
    "            # --- Update Decoder\n",
    "            decoderEmbeddingOutput = self.decoderEmbedding(np.array([sequence]))\n",
    "            decoderOutput, decoderStateH, decoderStateC = self.decoderLSTM(\n",
    "                decoderEmbeddingOutput,\n",
    "                initial_state = [\n",
    "                    states[i - 1][0],\n",
    "                    states[i - 1][1]\n",
    "                ]\n",
    "            )\n",
    "            # --- Ca Output\n",
    "            attentionOutput = self.attention([decoderOutput, encoderOutput])\n",
    "            modelOutput = self.outputDense(attentionOutput)\n",
    "            outputIdx = np.argmax(modelOutput[0][i - 1])\n",
    "            wordRes = idx2word[outputIdx]\n",
    "\n",
    "            # --- Update Variables\n",
    "            states[i] = [decoderStateH, decoderStateC]\n",
    "            sequence.append(outputIdx)\n",
    "                    \n",
    "            if wordRes == '<eos>':\n",
    "                break\n",
    "            \n",
    "            result.append(wordRes)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "model = Seq2seqModel(dictLength, 128, 128)\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.build(input_shape = (None, len(trainX), 128))\n",
    "\n",
    "model.load_weights(\"SavedModel/Seq2seqWithAttentionWeiht.h5\")\n",
    "print(\"Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(5):\n",
    "#     history = model.fit(\n",
    "#         [trainX, inputY],\n",
    "#         outputY,\n",
    "#         batch_size = 32,\n",
    "#         epochs = 1\n",
    "#     )\n",
    "#     model.save_weights(\"SavedModel/Seq2seqWithAttentionWeiht.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(\"SavedModel/Seq2seqWithAttentionWeiht.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('../Dataset/TextSummary/test.csv')\n",
    "dataX = testData['document']\n",
    "dataY = testData['summary']\n",
    "\n",
    "X, testY = [], []\n",
    "for line in dataX:\n",
    "    X.append(list(filter(CompareFunction, line.split())))\n",
    "\n",
    "for line in dataY:\n",
    "    testY.append(line.split())\n",
    "\n",
    "\n",
    "testX = []\n",
    "for sentence in X:\n",
    "    line = []\n",
    "    for word in sentence:\n",
    "        if word in words:\n",
    "            line.append(word2idx[word])\n",
    "        else:\n",
    "            line.append(word2idx['<unk>'])\n",
    "    testX.append([word2idx['<start>']] + line[0 : 70] + [word2idx['<eos>']] + [word2idx['<pad>']] * (70 - len(line)))\n",
    "testX = np.array(testX)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car kills including eight\n",
      "\n",
      "eight killed in bombing at philippines mall\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "predictY = model.ModelInferenceSingle(np.array([trainX[n]]), word2idx, idx2word, 20)\n",
    "print(' '.join(predictY[1: ]))\n",
    "print()\n",
    "print(' '.join(Y[n]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e1ff34b87b7117ec51074ce9135118c38474595f262d12cfb2c8fbe549e539"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
