{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "RANDOMSEED = 114 | 7\n",
    "\n",
    "data = pd.read_csv('../Database/emotionjudgemen.csv')\n",
    "data = shuffle(data, random_state = RANDOMSEED)\n",
    "\n",
    "Y, X = np.array(data['label']), np.array(data['review'])\n",
    "\n",
    "dataSize = len(X)\n",
    "baseCut = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary idx -> character; character -> idx\n",
    "char2idx = {}\n",
    "idx2char = {}\n",
    "vocabulary = []\n",
    "\n",
    "idx = 0\n",
    "meansSentenceLength = 0\n",
    "\n",
    "buf = 0\n",
    "\n",
    "for line in X:\n",
    "    meansSentenceLength += len(line)\n",
    "    for word in line:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "            char2idx[word] = idx\n",
    "            idx2char[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "meansSentenceLength /= idx\n",
    "\n",
    "\n",
    "systemWords = ['<EOS>', '<STA>', '<PAD>', '<UNK>']\n",
    "vocabulary += systemWords\n",
    "\n",
    "for word in systemWords:\n",
    "    char2idx[word] = idx\n",
    "    idx2char[idx] = word\n",
    "    idx += 1\n",
    "\n",
    "data = shuffle(data, random_state = RANDOMSEED)\n",
    "Y, X = np.array(data['label']), np.array(data['review'])\n",
    "trainX, trainY = X, Y\n",
    "# trainX, trainY = X[ : int(dataSize * baseCut)], Y[ : int(dataSize * baseCut)]\n",
    "testX, testY = X[int(dataSize * baseCut) :], Y[int(dataSize * baseCut) :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "padding the sentences and translate the sentences into indexs\n",
    "'''\n",
    "\n",
    "paddingLength = 60\n",
    "\n",
    "'''\n",
    "len = 10\n",
    "padL = 10\n",
    "start + 8 + end = 10\n",
    "\n",
    "len = 9\n",
    "padL = 10\n",
    "s + 7 + end = 9\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def Translate(sentence, paddingLength):\n",
    "    x = [char2idx['<STA>']] + [char2idx[word] for word in sentence] + [char2idx['<EOS>']] + [char2idx['<PAD>']] * paddingLength\n",
    "    return x[ : paddingLength]\n",
    "xBuf = []\n",
    "\n",
    "for i in range(len(trainX)):\n",
    "    xBuf.append(Translate(trainX[i], paddingLength))\n",
    "\n",
    "trainX = np.array(xBuf)\n",
    "\n",
    "xBuf = []\n",
    "for i in range(len(testX)):\n",
    "    xBuf.append(Translate(testX[i], paddingLength))\n",
    "\n",
    "testX = np.array(xBuf)\n",
    "\n",
    "trainY, testY = np.array(trainY), np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562\n"
     ]
    }
   ],
   "source": [
    "'''Renew the parameter'''\n",
    "dictSize = len(vocabulary)\n",
    "print(dictSize)\n",
    "embeddingOutlength = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# class JudgementaModel(keras.Model):\n",
    "#     def __init__(self, dictSize, outputDim):\n",
    "#         super(JudgementaModel, self).__init__()\n",
    "        \n",
    "#         self.embeddingLayer = keras.layers.Embedding(\n",
    "#             input_dim = dictSize,\n",
    "#             output_dim = outputDim\n",
    "#         )\n",
    "\n",
    "#         self.encoder = keras.layers.LSTM(\n",
    "#             units = 128,\n",
    "#             return_sequences = True,\n",
    "#             return_state = True\n",
    "#         )\n",
    "        \n",
    "#         self.transDense = keras.layers.Dense(\n",
    "#             units = 64,\n",
    "#             activation = 'relu'\n",
    "#         )\n",
    "\n",
    "#         self.dropOut = keras.layers.Dropout(0.3)\n",
    "\n",
    "#         self.outputDense = keras.layers.Dense(\n",
    "#             units = 2,\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         embeddingOutput = self.embeddingLayer(inputs)\n",
    "\n",
    "#         coderOutput, coderStateH, coderStateC = self.encoder(embeddingOutput)\n",
    "\n",
    "#         x = self.transDense(coderOutput)\n",
    "#         output = self.outputDense(x)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create the model'''\n",
    "# model = JudgementaModel(dictSize, 128)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        input_dim = dictSize,\n",
    "        output_dim = 128,\n",
    "    ),\n",
    "    \n",
    "    keras.layers.GRU(\n",
    "        units = 128,\n",
    "        activation = 'relu',\n",
    "        return_sequences = True\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.GRU(\n",
    "        units = 128,\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(\n",
    "        units = 64,\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(0.003),\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "132/132 [==============================] - 19s 120ms/step - loss: 0.5297 - accuracy: 0.7349 - val_loss: 0.3958 - val_accuracy: 0.8502\n",
      "Epoch 2/3\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.3583 - accuracy: 0.8694 - val_loss: 0.3524 - val_accuracy: 0.8543\n",
      "Epoch 3/3\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.2941 - accuracy: 0.8909 - val_loss: 0.3208 - val_accuracy: 0.8774\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('../SavedModel/EJ.h5'):\n",
    "    model.load_weights('../SavedModel/EJ.h5')\n",
    "\n",
    "history = model.fit(trainX, trainY, batch_size = 64, epochs = 3, validation_split = 0.3)\n",
    "\n",
    "model.save_weights('../SavedModel/EJ.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n",
      "[[0.00930882]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(np.array([testX[114]]))\n",
    "print(output)\n",
    "print(testY[114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "杂鱼杂鱼\n",
      "('正面评价', 0.82233304)\n"
     ]
    }
   ],
   "source": [
    "inputSentence = '杂鱼杂鱼'\n",
    "\n",
    "def Judgement(result):\n",
    "    return result > 0.5\n",
    "\n",
    "\n",
    "def GetResult(sentence):\n",
    "\n",
    "    inputIndexs = []\n",
    "    for w in sentence:\n",
    "        if w not in vocabulary:\n",
    "            inputIndexs.append(char2idx['<UNK>'])\n",
    "        else:\n",
    "            inputIndexs.append(char2idx[w])\n",
    "\n",
    "    inputIndexs = [char2idx['<STA>']] + inputIndexs + [char2idx['<EOS>']] + [char2idx['<PAD>']] * paddingLength\n",
    "\n",
    "    inputIndexs = inputIndexs[:paddingLength]\n",
    "\n",
    "    probability = model(np.array([inputIndexs])).numpy().reshape(1)[0]\n",
    "\n",
    "    if Judgement(probability): \n",
    "        return \"正面评价\", probability\n",
    "    return \"负面评价\", probability\n",
    "\n",
    "print(inputSentence)\n",
    "print(GetResult(inputSentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
